import json
import re

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
with open("../services/source_extractors.json", "r") as f:
    config = json.load(f)

# –ü—Ä–æ–≤–µ—Ä—è–µ–º Scale AI
source_config = config["extractors"]["scale"]
print(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞: {source_config['name']}")
print(f"URL: {source_config['url']}")
print(f"–°—Ç–∞—Ç—É—Å: {source_config['status']}")
print(f"–ü–∞—Ç—Ç–µ—Ä–Ω—ã: {source_config['patterns']}")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
with open("content_scale.md", "r") as f:
    content = f.read()

# –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
urls = set()
for pattern in source_config["patterns"]:
    matches = re.findall(pattern, content)
    urls.update(matches)

# –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ exclude_urls
filtered_urls = []
for url in urls:
    skip = False
    for exclude in source_config.get("exclude_urls", []):
        if exclude in url:
            skip = True
            break
    if not skip:
        filtered_urls.append(url)

print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(filtered_urls)} URL:")
for i, url in enumerate(filtered_urls[:5], 1):
    print(f"  {i}. {url}")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º Anthropic
print("\n" + "="*60)
source_config = config["extractors"]["anthropic"]
print(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞: {source_config['name']}")
print(f"–°—Ç–∞—Ç—É—Å: {source_config['status']}")

with open("content_anthropic.md", "r") as f:
    content = f.read()

urls = set()
for pattern in source_config["patterns"]:
    # –°–ª–æ–∂–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ç—Ä–µ–±—É—é—Ç –æ—Å–æ–±–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    if "\\\\\\\\\\\\\\\\s*\\n" in pattern:
        # –£–ø—Ä–æ—â–∞–µ–º –¥–ª—è —Ç–µ—Å—Ç–∞
        simple_pattern = r'\]\((https://www\.anthropic\.com/news/[^)]+)\)'
        matches = re.findall(simple_pattern, content)
    else:
        matches = re.findall(pattern, content)
    urls.update(matches)

print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(urls)} URL (–ø–µ—Ä–≤—ã–µ 5):")
for i, url in enumerate(list(urls)[:5], 1):
    print(f"  {i}. {url}")